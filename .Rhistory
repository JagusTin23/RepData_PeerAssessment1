grid.arrange(p3, p4, ncols=2)
grid.arrange(p3, p4, ncol=2)
head(mtcars)
mtcars[which(max(mtcars$mpg)),]
mtcars[which(mtcars$mpg == max(mtcars$mpg)),]
mtcars[which(mtcars$mpg > 25),]
mtcars[which(mtcars$mpg > 20),]
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
library(swirl)
swirl()
exit()
quit
quit()
pbeta(0.75, 2, 1)
?pbeta
?qbinom
qbeta(0.5, 2, 1)
library(swirl)
swirl()
2.5
1
sum(1:6)/6
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
0.5(edh + edl)
0.5(expect_dice(dice_low) + expect_dice(dice_high))
0.5*(edh + edl)
integrate(myfunc(0,2))
myfunc
integrate(myfunc, 0, 2)
spop
mean(spop)
allsam
apply(allsam, 1, mean)
mean(smean)
mean(smeans)
?swirl.install
install_from_swirl(Regression Models)
install_from_swirl("Regression Models")
swirl(0)
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
Sys.Date()
mean(c(2,4,5))
submit()
boring_function('My first function')
boring_function('My first function!')
boring_function()
boring_function
submit()
my_mean(c(4,5,10))
4%%3
12%4
12%%4
submit()
remainder(5)
remainder(11,5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1},6)
evaluate(function(x){x[1]}, c(8,4,0))
evaluate(function(x){x[length(x)]}, c(8,4,0))
?paste
type paste("Programming", "is", "fun!")
paste("Programming", "is", "fun!")
submit()
telegram("Feel the Bern")
submit()
mad_libs(place = "Puerto Rico", adjective = "10M", noun = "round of funding cuts")
submit()
"I"%p%"love"%p%"R!"
1-3/36
deck
help()
agrs(swirl)
hlp(0)
hlp()
52
4/52
0
12/52
2/51
.5*100
.5^1000
1/1000
*100
1/1000*100
library(AppliedPredictiveModeling)
install.package("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer)
head(train)
head(training)
hist(training$Superplasticizer)
summary(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(inTrain)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
head(inTrain)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
head(inTrain)
inTrain2 <- createDataPartition(adData$diagnosis, p = 3/4, list=FALSE)
head(inTrain2)
len(inTrain2)
length(inTrain2)
length(inTrain)
remove(inTrain2)
summary(training)
IL_vars <- grep("IL_", colnames(training))
IL_vars
colnames(training[,111]
)
head(training[,111])
summary(trainig[,111])
summary(training[,111])
str(training[,111])
colnames(training)
IL_vars <- grep("^IL_", colnames(training))
IL_vars
IL_vars2 <- grep("IL_", colnames(training))
IL_vars2
IL_vars2 !%in% IL_vars
!(IL_vars2 %in% IL_vars)
IL_vars2 <- grep("^IL", colnames(training))
IL_vars
IL_data <- training[, c("diagnosis", IL_vars2)]
IL_vars2 <- grep("^IL", colnames(training))
IL_data <- training[, c("diagnosis", IL_vars2)]
IL_data <- training[, c(1, IL_vars2)]
colnames(IL_data)
IL_data <- training[, c(IL_vars2)]
preProcess(IL_data, thresh= 0.80)
dim(IL_data)
summary(IL_data)
preProc <- preProcess(IL_data, method="pca", thresh= 0.80)
sampPC <- predict(preProc, IL_data)
dim(sampPC)
IL_data <- training[, c(1, IL_vars2)]
preProc <- preProcess(IL_data[,-1], method="pca", thresh= 0.80)
sampPC <- predict(preProc, IL_data)
sampPC <- predict(preProc, IL_data[,-1])
modelFit <- train(IL_data$diagnosis ~., method="glm", data=sampPC)
fit <- train(IL_data$diagnosis ~., method="glm", data=IL_data)
modelFit
fit
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_vars2 <- grep("^IL", colnames(training))
IL_data <- training[, c(1, IL_vars2)]
preProc <- preProcess(IL_data[,-1], method="pca", thresh= 0.80)
sampPC <- predict(preProc, IL_data[,-1])
modelFit <- train(IL_data$diagnosis ~., method="glm", data=sampPC)
fit <- train(IL_data$diagnosis ~., method="glm", data=IL_data)
test_IL <- testing[, c(1, IL_vars2)]
testPC <- predict(preProc, test_IL)
testPC <- predict(preProc, test_IL[,-1])
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
confusionMatrix(testing$diagnosis, predict(fit,test_IL))
preProc <- preProcess(IL_data[,-1], method="pca", thresh= 0.95)
preProc
preProc <- preProcess(IL_data[,-1], method="pca", thresh= 0.8)
preProc
preProc <- preProcess(IL_data[,-1], method="pca", thresh= 0.95)
preProc
sampPC <- predict(preProc, IL_data[,-1])
modelFit <- train(IL_data$diagnosis ~., method="glm", data=sampPC)
testPC <- predict(preProc, test_IL[,-1])
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
preProc <- preProcess(IL_data[,-1], method="pca", thresh= 0.80)
preProc
sampPC <- predict(preProc, IL_data[,-1])
modelFit <- train(IL_data$diagnosis ~., method="glm", data=sampPC)
test_IL <- testing[, c(1, IL_vars2)]
testPC <- predict(preProc, test_IL[,-1])
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
confusionMatrix(testing$diagnosis, predict(fit,testing))
confusionMatrix(testing$diagnosis, predict(fit,IL_data))
confusionMatrix(testing$diagnosis, predict(fit,test_IL))
mean(sum(1:6))
sum(1:6)/6
data(segmentationData)
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, !(Case == "Train"))
str(testing)
summary(testing)
training$Case <- NULL
testing$Case <- NULL
library(caret)
data(segmentationData)
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, !(Case == "Train"))
training$Case <- NULL
testing$Case <- NULL
library(rpart)
rpart1 <- rpart(Class ~., data = training, control = rpart.control(maxdepth=2))
rpart1
plot.rpart(rpart1)
par(xpd= TRUE)
plot(rpart1, compress=TRUE)
text(rpart1, use.n=TRUE)
library(partykit)
install.packages("partykit")
library(partykit)
library(grid)
library(partykit)
rpart1a <- as.party(rpart1)
plot(rpart1a)
rpartFull <- rpart(Class ~., data = training)
rpartFulla <- as.party(rpartFull)
plot(rpartFulla)
rpartFull
?train
library(caret)
library(partykit)
library(rpart)
?party
data(iris)
summmary(iris)
summary(iris)
inTrain <- createDataPartition(y = iris$Species, p=0.70, list=FALSE)
trainig <- iris[,inTrain]
trainig <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
training <- iris[inTrain,]
remove(trainig)
trainig
dim(training)
dim(testing)
qplot(Petal.Width, Sepal.width, colour=Species, data = training)
qplot(Petal.Width, Sepal.Width, colour=Species, data = training)
qplot(Petal.Length, Sepal.length, colour=Species, data = training)
qplot(Petal.Length, Sepal.Length, colour=Species, data = training)
qplot(Sepal.Width, Sepal.Length, colour=Species, data = training)
qplot(Sepal.Length, Sepal.Width, colour=Species, data = training)
featurePlot(x = training[,1:4], y = training$Species, plot="pairs", auto.key = list(columns=3))
auto.key = list(columns = 3))
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
transparentTheme(trans = .4)
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)
featurePlot(x = training[,1:4], y = training$Species, plot="pairs", auto.key = list(columns=3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
modFit <- train(Species ~ ., method="rpart", data=training)
modFit
modFit2 <- train(Species ~ ., data=training)
modFit2
library(partykit)
modFita <- as.party(modFit)
modFita <- as.party(modFit$finalModel)
modfit$finalModel
modFit$finalModel
plot(modFita)
modFit3 <- rpart(Species ~ ., data=training)
modFita <- as.party(modFit3)
plot(modFita)
predictions <- predict(modFit, testing)
cofusionMatrix(predictions,testing$species)
confusionMatrix(predictions,testing$species)
confusionMatrix(predictions,testing$Species)
predictRF <- predict(modFit2, testing)
confusionMatrix(predictRF,testing$Species)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
str(segmentationOriginal)
rpartFull
data(segmentationData)
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, !(Case == "Train"))
set.seed(125)
?rpart
modFit <- train(training$Class~., method="rpart", data=training)
modFit$finalModel
diag <- as.party(modFit$finalModel)
plot(diag)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
names(olibe)
names(olive)
olive = olive[,-1]
names(olive)
oliveFit <- train(Area~., method = "rpart", data=olive)
oliveFit$finalModel
predict(oliveFit, newdata = as.data.frame(t(colMeans(olive))))
summary (olive$Area)
hist(olive$Area)
str(olive$Area)
unique(olive$Area)
olive$Area <- as.factor(olive$Area)
oliveFit <- train(Area~., method = "rpart", data=olive)
predict(oliveFit, newdata = as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
library(ISLR)
data(SAheart)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
trainControl
?trainControl
?train
regFit <- train(chd ~ age + alcohol + obesity + tabacco + typea + ldl, method = "glm", family="binomial", data=trainSA)
regFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", family="binomial", data=trainSA)
regFit$finalModel
str(trainSA$chd)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(training, regFit)
missClass(trainSA, regFit)
predTrain <- predict(regFit, trainSA)
missClass(trainSA$chd, predTrain)
predTest <- predict(regFit, testSA)
missClass(testSA$chd, predTest)
data(vowel.train)
data(vowel.test)
str(vowel.train)
str(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
?varImp
modRF <- train(y ~., data=vowel.train)
varImp(modRF)
head(iris)
dim(iris)
data(iris)
library(caret)
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)
featurePlot(x = training[,1:4], y = training$Species, plot="pairs", auto.key = list(columns=3))
data(iris)
inTrain <- createDataPartition(y = iris$Species, p=0.70, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
featurePlot(x = training[,1:4], y = training$Species, plot="pairs", auto.key = list(columns=3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
?train
modFit <- train(Species ~ ., method="rpart", data=training)
modFit2 <- train(Species ~ ., data=training)
predictionsRpart <- predict(modFit, testing)
predictRF <- predict(modFit2, testing)
confusionMatrix(predictRF,testing$Species)
summary(iris)
str(iris)
confusionMatric(predictRpart, testing$Species)
confusionMatrix(predictRpart, testing$Species)
confusionMatrix(predictionsRpart, testing$Species)
confusionMatrix(predictRF,testing$Species)
modFit2$finalModel
?randomForest
library(party)
modFita <- as.party(modFit2)
?as.party
??as.party
modFita <- as.party(modFit3)
library(partykit)
modFita <- as.party(modFit3)
modFit3 <- rpart(Species ~ ., data=training)
modFita <- as.party(modFit3)
plot(modFita)
modFita <- as.party(modFit2)
modFita <- as.party(modFit)
modFita <- as.party(modFit3$finalModel)
modFita <- as.party(modFit2$finalModel)
modFita <- as.party(modFit$finalModel)
plot(modFita)
modFit3$finalModel
modFit2$finalModel
dim(training)
model_rf <- train(Species ~ ., data=trainig, method = "rf", trControl=trainControl(method="cv", numbers=5), prox= TRUE, allowParallel= TRUE)
model_rf <- train(Species ~ ., data=training, method = "rf", trControl=trainControl(method="cv", numbers=5), prox= TRUE, allowParallel= TRUE)
model_rf <- train(Species ~ ., data=training, method = "rf", trControl=trainControl(method="cv", number=5), prox= TRUE, allowParallel= TRUE)
model_rf$finalModel
predictRFcv <- predict(model_rf, testing)
confusionMatrix(predictRFcv, testing$Species)
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
1/1000
library(ggplot2)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
dim(training)
names(training)
hist(training$make)
hist(training$num650)
hist(training$num415)
head(training$edu)
head(training$table)
modelFit$finalModel
modelFit
modrf <- train(type~., data=training)
predict.rf <- predict(modrf, newdata=testing)
confusionMatrix(predictions, testing$type)
predictions <- predict(modelFit, newdata=testing)
confusionMatrix(predictions, testing$type)
confusionMatrix(predict.rf, testing$type)
modrf
?random.forest
?randomforest
?randomForest
modrf$finalModel
args(train.default)
getwd(0)
getwd()
setwd("./desktop/rcoursera/reprores")
list.files()
setwd("./RepData_PeerAssessment1")
list.files()
data2 <- read.csv(file, header = TRUE, stringsAsFactor = FALSE)
file <- "activity.csv"
data2 <- read.csv(file, header = TRUE, stringsAsFactor = FALSE)
data2$steps <- ifelse(is.na(data2$steps), mean(data2$steps, na.rm = TRUE), data2$steps)
head(wkdata)
weekend <- c("Saturday", "Sunday")
data2$wkday <- factor((weekdays(data2$date) %in% weekend), levels=c(FALSE, TRUE), labels=c('weekday', 'weekend'))
library(lubridate)
data2$wkday <- factor((weekdays(data2$date) %in% weekend), levels=c(FALSE, TRUE), labels=c('weekday', 'weekend'))
data2 <- read.csv(file, header = TRUE, stringsAsFactor = FALSE)
data2$steps <- ifelse(is.na(data2$steps), mean(data2$steps, na.rm = TRUE), data2$steps)
data2$date <- ymd(data2$date)
new_data <- aggregate(steps~date, data2, sum)
weekend <- c("Saturday", "Sunday")
data2$wkday <- factor((weekdays(data2$date) %in% weekend), levels=c(FALSE, TRUE), labels=c('weekday', 'weekend'))
wkdata <- aggregate(steps~interval+wkday, data2, FUN=mean)
head(wkdata)
means <- wkdata %>% group_by(wkday) %>% summarize(mean = mean(steps))
library(dplyr)
means <- wkdata %>% group_by(wkday) %>% summarize(mean = mean(steps))
means
means <- wkdata %>% group_by(wkday) %>% summarize(sum = sum(steps))
means
